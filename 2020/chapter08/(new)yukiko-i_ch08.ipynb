{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 データの入手・整形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む． 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する． 抽出された事例をランダムに並び替える． 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）． 学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b02390c7677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTKINTER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;31m#/////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(input_file):\n",
    "    target_publisher_set = {\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"}\n",
    "    extracted_data = []\n",
    "    with open(input_file, \"r\") as fi:\n",
    "        for line in fi:\n",
    "            data = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            publisher = data[3]\n",
    "            if publisher in target_publisher_set:\n",
    "                extracted_data.append(data)\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = extract_data(\"./data/newsCorpora.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_data(extracted_data, output_dir):\n",
    "    random.shuffle(extracted_data)\n",
    "    train_data, valid_and_test_data = train_test_split(extracted_data, test_size=0.2)\n",
    "    valid_data, test_data = train_test_split(valid_and_test_data, test_size=0.5)\n",
    "    train_file = os.path.join(output_dir, \"train.txt\")\n",
    "    valid_file = os.path.join(output_dir, \"valid.txt\")\n",
    "    test_file = os.path.join(output_dir, \"test.txt\")\n",
    "    with open(train_file, \"w\") as fo:\n",
    "        for data in train_data:\n",
    "            fo.write(\"{}\\t{}\\n\".format(data[4], data[1]))\n",
    "    with open(valid_file, \"w\") as fo:\n",
    "        for data in valid_data:\n",
    "            fo.write(\"{}\\t{}\\n\".format(data[4], data[1]))\n",
    "    with open(test_file, \"w\") as fo:\n",
    "        for data in test_data:\n",
    "            fo.write(\"{}\\t{}\\n\".format(data[4], data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(extracted_data, \"work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xiの特徴ベクトルxiを並べた行列Xと，正解ラベルを並べた行列（ベクトル）Yを作成したい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def convert_dataset_to_vector(word_vectors_model, input_file, label2id, x_output_file, y_output_file):\n",
    "    x_vectors = []\n",
    "    y_vectors = []\n",
    "    \n",
    "    with open(input_file, \"r\") as fi:\n",
    "        for line in fi:\n",
    "            text, label = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            tokens = word_tokenize(text)\n",
    "            vectors = []\n",
    "            for token in tokens:\n",
    "                try: # 単語ベクトルの中に含まれているものだけ抽出\n",
    "                    vector = word_vectors_model[token]\n",
    "                    vectors.append(vector)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if not vectors:\n",
    "                continue\n",
    "            ave_vector = np.mean(vectors, axis=0)\n",
    "            x_vectors.append(ave_vector)\n",
    "            label_id = label2id[label]\n",
    "            y_vectors.append(label_id)\n",
    "        x_vectors = np.array(x_vectors)\n",
    "        y_vectors = np.array(y_vectors)\n",
    "        \n",
    "    print(\"x shape:{}\\ty shape:{}\".format(x_vectors.shape, y_vectors.shape))\n",
    "    np.save(x_output_file, x_vectors)\n",
    "    np.save(y_output_file, y_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors_path = './data/GoogleNews-vectors-negative300.bin'\n",
    "word_vectors_model = KeyedVectors.load_word2vec_format(word_vectors_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"b\":0, \"t\":1, \"e\":2, \"m\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:(10684, 300)\ty shape:(10684,)\n",
      "x shape:(1336, 300)\ty shape:(1336,)\n",
      "x shape:(1336, 300)\ty shape:(1336,)\n"
     ]
    }
   ],
   "source": [
    "convert_dataset_to_vector(word_vectors_model, \"./data/train.txt\", label2id, \"./work/train_x.npy\", \"./work/train_y.npy\")\n",
    "convert_dataset_to_vector(word_vectors_model, \"./data/valid.txt\", label2id, \"./work/valid_x.npy\", \"./work/valid_y.npy\")\n",
    "convert_dataset_to_vector(word_vectors_model, \"./data/test.txt\", label2id, \"./work/test_x.npy\", \"./work/test_y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, num_class):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim, num_class, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = self.l1(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=300, num_class=4)\n",
    "train_x = np.load(\"./work/train_x.npy\")\n",
    "train_y = np.load(\"./work/train_y.npy\")\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2463, 0.2474, 0.2631, 0.2432], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = softmax(model.forward(train_x[0]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2463, 0.2474, 0.2631, 0.2432],\n",
      "        [0.2433, 0.2523, 0.2641, 0.2404],\n",
      "        [0.2546, 0.2586, 0.2533, 0.2334],\n",
      "        [0.2569, 0.2462, 0.2579, 0.2390]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = softmax(model.forward(train_x[:4]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, num_class):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim, num_class, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = self.l1(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=300, num_class=4)\n",
    "train_x = np.load(\"./work/train_x.npy\")\n",
    "train_y = np.load(\"./work/train_y.npy\")\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3753, grad_fn=<NllLossBackward>)\n",
      "tensor([[-0.0362, -0.0386,  0.0032,  ...,  0.0012, -0.0091,  0.0117],\n",
      "        [ 0.0194,  0.0118,  0.0119,  ..., -0.0111,  0.0052,  0.0020],\n",
      "        [ 0.0029,  0.0008, -0.0059,  ...,  0.0058,  0.0012, -0.0024],\n",
      "        [ 0.0138,  0.0260, -0.0093,  ...,  0.0042,  0.0028, -0.0113]])\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "logit = model.forward(train_x[:4])\n",
    "loss = loss_func(logit, train_y[:4])\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(model.l1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "def train(output_file, num_epoch, train_x_file, train_y_file, learning_rate):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    train_x = torch.from_numpy(train_x)\n",
    "    train_y = torch.from_numpy(train_y)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset)\n",
    "    model = Model(input_dim=300, num_class=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    #訓練\n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        total_loss = 0\n",
    "        for x, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            logit = model.forward(x)\n",
    "            loss = loss_func(logit, y)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        ave_loss = total_loss / len(train_x)\n",
    "        print(\"Epoch:{}\\tave_loss:{}\".format(epoch, ave_loss))\n",
    "    torch.save(model.state_dict(), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\tave_loss:0.6828608990943538\n",
      "Epoch:2\tave_loss:0.47088235313140053\n",
      "Epoch:3\tave_loss:0.41033400815531706\n",
      "Epoch:4\tave_loss:0.37844074632326846\n",
      "Epoch:5\tave_loss:0.3582469477335565\n",
      "Epoch:6\tave_loss:0.34403683642118316\n",
      "Epoch:7\tave_loss:0.33333511975064123\n",
      "Epoch:8\tave_loss:0.3248883714403976\n",
      "Epoch:9\tave_loss:0.3179894401943489\n",
      "Epoch:10\tave_loss:0.3122065503517621\n"
     ]
    }
   ],
   "source": [
    "train(\"./work/model.pt\", 10, \"./work/train_x.npy\", \"./work/train_y.npy\", 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def evaluate(model_file, x_file, y_file):\n",
    "    x_data = np.load(x_file)\n",
    "    y_data = np.load(y_file)\n",
    "    x_data = torch.from_numpy(x_data)\n",
    "    y_data = torch.from_numpy(y_data)\n",
    "    dataset = torch.utils.data.TensorDataset(x_data, y_data)\n",
    "    data_iter = torch.utils.data.DataLoader(dataset)\n",
    "    model = Model(input_dim=300, num_class=4)\n",
    "    model.load_state_dict(torch.load(model_file)) # 訓練済みのモデルをロード\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    for x, y in data_iter:\n",
    "        logit = model.forward(x)\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.8964807188318982\n",
      "test accuracy:0.8952095808383234\n"
     ]
    }
   ],
   "source": [
    "train_acc = evaluate(\"./work/model.pt\", \"./work/train_x.npy\", \"./work/train_y.npy\")\n",
    "print(\"train accuracy:{}\".format(train_acc))\n",
    "test_acc = evaluate(\"./work/model.pt\", \"./work/test_x.npy\", \"./work/test_y.npy\")\n",
    "print(\"test accuracy:{}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "\n",
    "def calc_loss_and_accuracy(model, loss_func, dataset):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    for x, y in dataset:\n",
    "        logit = model.forward(x)\n",
    "        loss = loss_func(logit, y)\n",
    "        total_loss += loss.item()\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    ave_loss = total_loss / len(dataset)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return ave_loss, accuracy\n",
    "    \n",
    "    \n",
    "def train(num_epoch, learning_rate, train_x_file, train_y_file, valid_x_file, valid_y_file, output_file, log_file):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    valid_x = np.load(valid_x_file)\n",
    "    valid_y = np.load(valid_y_file)\n",
    "    train_x = torch.from_numpy(train_x)\n",
    "    train_y = torch.from_numpy(train_y)\n",
    "    valid_x = torch.from_numpy(valid_x)\n",
    "    valid_y = torch.from_numpy(valid_y)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid_dataset = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset)\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_dataset)\n",
    "    model = Model(input_dim=300, num_class=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    with open(log_file, \"w\") as f_log:\n",
    "        f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\"))\n",
    "        # 訓練\n",
    "        print(\"Training Start\")\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(\"Epoch\", \"Train_loss\", \"Train_acc\", \"Valid_loss\", \"Valid_acc\"))\n",
    "        for epoch in range(1, num_epoch+1):\n",
    "            for x, y in train_iter:\n",
    "                optimizer.zero_grad()\n",
    "                logit = model.forward(x)\n",
    "                loss = loss_func(logit, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # 評価\n",
    "            train_loss, train_acc = calc_loss_and_accuracy(model, loss_func, train_iter)\n",
    "            valid_loss, valid_acc = calc_loss_and_accuracy(model, loss_func, valid_iter)\n",
    "            print(\"Epoch:{}\\t{}\\t{}\\t{}\\t{}\".format(epoch, train_loss, train_acc, valid_loss, valid_acc))\n",
    "            f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "        torch.save(model.state_dict(), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "Epoch\tTrain_loss\tTrain_acc\tValid_loss\tValid_acc\n",
      "Epoch:1\t0.5213235759294037\t0.8157057281916885\t0.5350950387875343\t0.8016467065868264\n",
      "Epoch:2\t0.4324924043759599\t0.8558592287532759\t0.44756538830748077\t0.8383233532934131\n",
      "Epoch:3\t0.39094242936432577\t0.871115687008611\t0.4073476682476871\t0.8592814371257484\n",
      "Epoch:4\t0.3662719346086843\t0.88131785847997\t0.3840342477722592\t0.8675149700598802\n",
      "Epoch:5\t0.34959537736403995\t0.8861849494571321\t0.36872050971194625\t0.8735029940119761\n",
      "Epoch:6\t0.3373740580638377\t0.8901160614002246\t0.357857820356286\t0.875\n",
      "Epoch:7\t0.3279155810524871\t0.8920816173717708\t0.3497464616225688\t0.8794910179640718\n",
      "Epoch:8\t0.3203038599396507\t0.8939535754399102\t0.3434645534345261\t0.8824850299401198\n",
      "Epoch:9\t0.3139967526661416\t0.8949831523773868\t0.3384657861250034\t0.8824850299401198\n",
      "Epoch:10\t0.30865123424859964\t0.8956383377012355\t0.334404398213687\t0.8824850299401198\n"
     ]
    }
   ],
   "source": [
    "train(10, 0.01, \"./work/train_x.npy\", \"./work/train_y.npy\", \"./work/valid_x.npy\", \"./work/valid_y.npy\", \"./work/model75.pt\", \"./work/log75.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasでグラフ作成\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./work/log.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517239</td>\n",
       "      <td>0.823662</td>\n",
       "      <td>0.525421</td>\n",
       "      <td>0.827844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429146</td>\n",
       "      <td>0.862411</td>\n",
       "      <td>0.441278</td>\n",
       "      <td>0.863772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.387735</td>\n",
       "      <td>0.876638</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>0.878743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363047</td>\n",
       "      <td>0.884875</td>\n",
       "      <td>0.382318</td>\n",
       "      <td>0.884731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.346310</td>\n",
       "      <td>0.889274</td>\n",
       "      <td>0.368379</td>\n",
       "      <td>0.889222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  valid_loss  valid_acc\n",
       "0    0.517239   0.823662    0.525421   0.827844\n",
       "1    0.429146   0.862411    0.441278   0.863772\n",
       "2    0.387735   0.876638    0.403713   0.878743\n",
       "3    0.363047   0.884875    0.382318   0.884731\n",
       "4    0.346310   0.889274    0.368379   0.889222"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df[[\"train_acc\", \"valid_acc\"]].plot()\n",
    "ax.set_title(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df[[\"train_loss\", \"valid_loss\"]].plot()\n",
    "ax.set_title(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 76. チェックポイント\n",
    "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#チェックポイントとして、重み行列の値と最適化アルゴリズムの内部状態をファイルに書き込む        \n",
    "def calc_loss_and_accuracy(model, loss_func, dataset):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    for x, y in dataset:\n",
    "        logit = model.forward(x)\n",
    "        loss = loss_func(logit, y)\n",
    "        total_loss += loss.item()\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    ave_loss = total_loss / len(dataset)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return ave_loss, accuracy\n",
    "    \n",
    "def train(num_epoch, learning_rate, train_x_file, train_y_file, valid_x_file, valid_y_file, output_file, log_file):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    valid_x = np.load(valid_x_file)\n",
    "    valid_y = np.load(valid_y_file)\n",
    "    train_x = torch.from_numpy(train_x)\n",
    "    train_y = torch.from_numpy(train_y)\n",
    "    valid_x = torch.from_numpy(valid_x)\n",
    "    valid_y = torch.from_numpy(valid_y)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid_dataset = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset)\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_dataset)\n",
    "    model = Model(input_dim=300, num_class=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    with open(log_file, \"w\") as f_log:\n",
    "        f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\"))\n",
    "        # 訓練\n",
    "        print(\"Training Start\")\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(\"Epoch\", \"Train_loss\", \"Train_acc\", \"Valid_loss\", \"Valid_acc\"))\n",
    "        for epoch in range(1, num_epoch+1):\n",
    "            for x, y in train_iter:\n",
    "                optimizer.zero_grad()\n",
    "                logit = model.forward(x)\n",
    "                loss = loss_func(logit, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # 評価\n",
    "            train_loss, train_acc = calc_loss_and_accuracy(model, loss_func, train_iter)\n",
    "            valid_loss, valid_acc = calc_loss_and_accuracy(model, loss_func, valid_iter)\n",
    "            print(\"Epoch:{}\\t{}\\t{}\\t{}\\t{}\".format(epoch, train_loss, train_acc, valid_loss, valid_acc))\n",
    "            f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "            \n",
    "        #model.state_dictメソッドでモデルのパラメータを保存できる\n",
    "        #optimizer.state_dict()→内部状態を保存するメソッド\n",
    "        torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()} , output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "Epoch\tTrain_loss\tTrain_acc\tValid_loss\tValid_acc\n",
      "Epoch:1\t0.5203304422622188\t0.8154249344814676\t0.5337872897260153\t0.8016467065868264\n",
      "Epoch:2\t0.4317631861800417\t0.8571695994009734\t0.4467609699394073\t0.8398203592814372\n",
      "Epoch:3\t0.3904088094642346\t0.8713028828154249\t0.40682386865145403\t0.8592814371257484\n",
      "Epoch:4\t0.3658613336122126\t0.8817858479970049\t0.38366374280708904\t0.8667664670658682\n",
      "Epoch:5\t0.3492659562953289\t0.8872145263946087\t0.36844050845793447\t0.8712574850299402\n",
      "Epoch:6\t0.3371012263329376\t0.8897416697865967\t0.3576352159457773\t0.875\n",
      "Epoch:7\t0.32768406134240063\t0.8926432047922127\t0.34956237789002786\t0.8787425149700598\n",
      "Epoch:8\t0.3201036311475094\t0.8939535754399102\t0.3433077363987279\t0.8824850299401198\n",
      "Epoch:9\t0.31382092654684485\t0.8950767502807937\t0.33832918288913094\t0.8832335329341318\n",
      "Epoch:10\t0.30849491294242976\t0.8963871209284912\t0.3342832680263817\t0.8832335329341318\n"
     ]
    }
   ],
   "source": [
    "train(10, 0.01, \"./work/train_x.npy\", \"./work/train_y.npy\", \"./work/valid_x.npy\", \"./work/valid_y.npy\", \"./work/model76.pt\", \"./work/log76.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_state_dict': OrderedDict([('l1.weight', tensor([[-0.4233, -0.0917, -0.1502,  ...,  0.2818,  0.2262, -0.7437],\n",
      "        [ 0.3361,  0.1776,  0.5988,  ..., -0.0393, -0.6740, -0.4723],\n",
      "        [ 0.5205,  0.0892, -1.0334,  ..., -0.6633,  0.0559,  0.3182],\n",
      "        [-0.3700, -0.1506,  0.5157,  ...,  0.3028,  0.4610,  0.8636]]))]), 'optimizer_state_dict': {'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}]}}\n"
     ]
    }
   ],
   "source": [
    "#ファイルを読み込んで確認\n",
    "output_f = \"./work/model76.pt\"\n",
    "check_point = torch.load(output_f)\n",
    "print(check_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 77. ミニバッチ化\n",
    "問題76のコードを改変し，B事例ごとに損失・勾配を計算し，行列Wの値を更新せよ（ミニバッチ化）．Bの値を1,2,4,8,…と変化させながら，1エポックの学習に要する時間を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータの更新に全ての訓練データを用いるのがバッチ学習\n",
    "#それに対して一部の訓練データを取り出すのがミニバッチ学習\n",
    "\n",
    "import time\n",
    "def calc_loss_and_accuracy(model, loss_func, dataset):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x, y in dataset:\n",
    "        logit = model.forward(x)\n",
    "        loss = loss_func(logit, y)\n",
    "        total_loss += loss.item()\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    ave_loss = total_loss / len(dataset)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return ave_loss, accuracy\n",
    "      \n",
    "def train(batch_size, num_epoch, learning_rate, train_x_file, train_y_file, valid_x_file, valid_y_file, output_file, log_file):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    valid_x = np.load(valid_x_file)\n",
    "    valid_y = np.load(valid_y_file)\n",
    "    train_x = torch.from_numpy(train_x).float()\n",
    "    train_y = torch.from_numpy(train_y).long()\n",
    "    valid_x = torch.from_numpy(valid_x).float()\n",
    "    valid_y = torch.from_numpy(valid_y).long()\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid_dataset = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_dataset)\n",
    "    model = Model(input_dim=300, num_class=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    with open(log_file, \"w\") as f_log:\n",
    "        f_log.write(\"{}\\n\".format(\"batch_size\"))\n",
    "        # 訓練 \n",
    "        for epoch in range(1, num_epoch+1):\n",
    "            \n",
    "            #時間を記録\n",
    "            start = time.time()\n",
    "            for x, y in train_iter:\n",
    "                optimizer.zero_grad()\n",
    "                logit = model.forward(x)\n",
    "                loss = loss_func(logit, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            #終了時刻\n",
    "            end = time.time()\n",
    "            total_time = end - start\n",
    "            print(\"Batch_size:{}\\t{}\".format(batch_size, total_time))\n",
    "            f_log.write(\"{}\\t{}\\n\".format(batch_size, total_time))\n",
    "            \n",
    "        #model.state_dictメソッドでモデルのパラメータを保存できる\n",
    "        #optimizer.state_dict()→内部状態を保存するメソッド\n",
    "        torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()} , output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:1\t2.2845213413238525\n",
      "Batch_size:2\t1.2452478408813477\n",
      "Batch_size:4\t0.6073892116546631\n",
      "Batch_size:8\t0.35704827308654785\n",
      "Batch_size:16\t0.23964905738830566\n",
      "Batch_size:32\t0.16015195846557617\n",
      "Batch_size:64\t0.12971782684326172\n",
      "Batch_size:128\t0.13903307914733887\n",
      "Batch_size:256\t0.10283017158508301\n",
      "Batch_size:512\t0.09129524230957031\n"
     ]
    }
   ],
   "source": [
    "#バッチサイズを指定\n",
    "for batch_size in [ 2 ** i for i in range(10)]:\n",
    "    train(batch_size, 1, 0.01, \"./work/train_x.npy\", \"./work/train_y.npy\", \"./work/valid_x.npy\", \"./work/valid_y.npy\"model, \"./work/model77.pt\", \"./work/log77.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 78. GPU上での学習\n",
    "問題77のコードを改変し，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 乾研サーバーの環境構築が終わっていなかった為割愛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習に要する時間の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 79. 多層ニューラルネットワーク\n",
    "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#多層化したモデルの定義(隠れ層を追加)\n",
    "class Multipled_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Multipled_model, self).__init__()\n",
    "        #Linearは全結合層を示す\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        logit = self.fc2(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calc_loss_and_accuracy(model, loss_func, dataset):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    for x, y in dataset:\n",
    "        logit = model.forward(x)\n",
    "        loss = loss_func(logit, y)\n",
    "        total_loss += loss.item()\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    ave_loss = total_loss / len(dataset)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return ave_loss, accuracy\n",
    "    \n",
    "def train(batch_size, num_epoch, learning_rate, train_x_file, train_y_file, valid_x_file, valid_y_file, output_file, log_file):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    valid_x = np.load(valid_x_file)\n",
    "    valid_y = np.load(valid_y_file)\n",
    "    train_x = torch.from_numpy(train_x).float()\n",
    "    train_y = torch.from_numpy(train_y).long()\n",
    "    valid_x = torch.from_numpy(valid_x).float()\n",
    "    valid_y = torch.from_numpy(valid_y).long()\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid_dataset = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset,shuffle = True)\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_dataset)\n",
    "    model = Multipled_model(input_dim=300, hidden_dim=100,output_dim=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #optimizerを変更\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "         \n",
    "    with open(log_file, \"w\") as f_log:\n",
    "        f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\"))\n",
    "        # 訓練 \n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(\"Epoch\", \"Train_loss\", \"Train_acc\", \"Valid_loss\", \"Valid_acc\"))\n",
    "        for epoch in range(1, num_epoch+1):\n",
    "            \n",
    "            for x, y in train_iter:\n",
    "                optimizer.zero_grad()\n",
    "                logit = model(x)\n",
    "                loss = loss_func(logit, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            #評価\n",
    "            train_loss, train_acc = calc_loss_and_accuracy(model, loss_func, train_iter)\n",
    "            valid_loss, valid_acc = calc_loss_and_accuracy(model, loss_func, valid_iter)\n",
    "            print(\"Epoch:{}\\t{}\\t{}\\t{}\\t{}\".format(epoch, train_loss, train_acc, valid_loss, valid_acc))\n",
    "            f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "            \n",
    "        #model.state_dictメソッドでモデルのパラメータを保存できる\n",
    "        #optimizer.state_dict()→内部状態を保存するメソッド\n",
    "        torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()} , output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\tTrain_loss\tTrain_acc\tValid_loss\tValid_acc\n",
      "Epoch:1\t0.2857771837839182\t0.9041557469112692\t0.3809893997890397\t0.8869760479041916\n",
      "Epoch:2\t0.31657333208247185\t0.8925496068888057\t0.4296295026250836\t0.8712574850299402\n",
      "Epoch:3\t0.2501529350781316\t0.9181954324223137\t0.39222289153820217\t0.8862275449101796\n",
      "Epoch:4\t0.22686568033961552\t0.9208161737177087\t0.376537689733234\t0.8907185628742516\n",
      "Epoch:5\t0.23717222906005192\t0.9213777611381505\t0.509250994178514\t0.8787425149700598\n",
      "Epoch:6\t0.24779755275363682\t0.9281168101834519\t0.5371936573470764\t0.8899700598802395\n",
      "Epoch:7\t0.19492646393880142\t0.9287719955073006\t0.4646183300114005\t0.8899700598802395\n",
      "Epoch:8\t0.20463245939227612\t0.9204417821040809\t0.529132636401041\t0.8675149700598802\n",
      "Epoch:9\t0.17043693858159875\t0.9417821040808686\t0.5886486208180495\t0.8817365269461078\n",
      "Epoch:10\t0.15687281495447813\t0.9480531636091352\t0.6497314538800224\t0.8839820359281437\n",
      "Epoch:11\t0.1673355713754052\t0.9475851740921003\t0.6982767493958552\t0.8802395209580839\n",
      "Epoch:12\t0.1441500314141516\t0.9496443279670536\t0.6632903796285446\t0.8869760479041916\n",
      "Epoch:13\t0.13238306984972714\t0.9559153874953201\t0.7711323073768954\t0.8869760479041916\n",
      "Epoch:14\t0.15093933138425908\t0.943373268438787\t0.7407380756064492\t0.8705089820359282\n",
      "Epoch:15\t0.10921706299030183\t0.9630288281542494\t0.8710431011461651\t0.8884730538922155\n",
      "Epoch:16\t0.10706469662963981\t0.961344065892924\t0.7900083559880838\t0.8989520958083832\n",
      "Epoch:17\t0.12522300328262598\t0.9563833770123549\t0.827326817318851\t0.8735029940119761\n",
      "Epoch:18\t0.14811681623643813\t0.9546050168476227\t1.1614736363512217\t0.8779940119760479\n",
      "Epoch:19\t0.08675778652583231\t0.969112691875702\t0.845559760478353\t0.8907185628742516\n",
      "Epoch:20\t0.10253138478139108\t0.9660239610632722\t1.1077026964030945\t0.8854790419161677\n",
      "Epoch:21\t0.09363580944305396\t0.9705166604268064\t1.101045201963954\t0.8809880239520959\n",
      "Epoch:22\t0.11479100309979183\t0.9647135904155747\t1.3718192611914684\t0.8899700598802395\n",
      "Epoch:23\t0.09076517875651857\t0.9692062897791089\t1.2965156258739978\t0.8944610778443114\n",
      "Epoch:24\t0.13240607682856367\t0.9609696742792961\t1.544698331630022\t0.8832335329341318\n",
      "Epoch:25\t0.08771667901721089\t0.9704230625233995\t1.2811416212320816\t0.8869760479041916\n",
      "Epoch:26\t0.11299071710520138\t0.9676151254211905\t1.600682347162201\t0.8877245508982036\n",
      "Epoch:27\t0.08037789396784938\t0.9757581430175964\t1.2677903132331323\t0.8869760479041916\n",
      "Epoch:28\t0.08002997185400333\t0.9734181954324224\t1.4944519995699805\t0.8847305389221557\n",
      "Epoch:29\t0.1168052921589004\t0.9673343317109697\t1.7710968061704844\t0.8787425149700598\n",
      "Epoch:30\t0.06353514734371957\t0.9771621115687008\t1.6888236206821583\t0.8862275449101796\n",
      "Epoch:31\t0.07188973718351883\t0.9751029576937477\t1.7614530384232656\t0.8899700598802395\n",
      "Epoch:32\t0.08195111318265311\t0.9747285660801198\t1.784748486613396\t0.8772455089820359\n",
      "Epoch:33\t0.0878124722075191\t0.9728566080119805\t2.000745694723597\t0.8772455089820359\n",
      "Epoch:34\t0.061544779132806045\t0.976787719955073\t1.6568144841661314\t0.8862275449101796\n",
      "Epoch:35\t0.10661335285653896\t0.9752901535005616\t1.7329646831660115\t0.8944610778443114\n",
      "Epoch:36\t0.07889273395148395\t0.9754773493073755\t2.214844506701999\t0.8764970059880239\n",
      "Epoch:37\t0.05130749959627854\t0.9831523773867465\t2.1441947463554465\t0.8817365269461078\n",
      "Epoch:38\t0.06529709966319507\t0.9774429052789217\t2.0542213673361043\t0.8779940119760479\n",
      "Epoch:39\t0.08504335860204953\t0.9775365031823288\t2.541716871336455\t0.8824850299401198\n",
      "Epoch:40\t0.07268738253863906\t0.9781916885061774\t2.492692307123299\t0.8809880239520959\n",
      "Epoch:41\t0.058891039677291146\t0.9790340696368401\t2.527827074706114\t0.8832335329341318\n",
      "Epoch:42\t0.06562221624563515\t0.9763197304380382\t2.4310981773107456\t0.8772455089820359\n",
      "Epoch:43\t0.05286556448866687\t0.9812804193186072\t2.3863901318933567\t0.8832335329341318\n",
      "Epoch:44\t0.0715034598498878\t0.979314863347061\t3.0220735576315447\t0.8764970059880239\n",
      "Epoch:45\t0.11138373403206127\t0.9790340696368401\t3.1468539908808735\t0.8839820359281437\n",
      "Epoch:46\t0.0477470609973143\t0.9836203669037814\t2.6074582231317907\t0.8779940119760479\n",
      "Epoch:47\t0.05056754154453884\t0.9836203669037814\t2.8507360004528417\t0.875748502994012\n",
      "Epoch:48\t0.05571971294602228\t0.9817484088356421\t3.0356922728101425\t0.8787425149700598\n",
      "Epoch:49\t0.06467512844483392\t0.9805316360913515\t2.7393292396353894\t0.8824850299401198\n",
      "Epoch:50\t0.06912155164702372\t0.9772557094721078\t2.883969316670582\t0.8832335329341318\n",
      "Epoch:51\t0.05540763810858138\t0.9841819543242232\t2.935689155803064\t0.8832335329341318\n",
      "Epoch:52\t0.08538548258049314\t0.9747285660801198\t3.1214441009766394\t0.8839820359281437\n",
      "Epoch:53\t0.03855767781055809\t0.9867090977162112\t3.155712795011473\t0.8787425149700598\n",
      "Epoch:54\t0.0466416535610468\t0.9838075627105953\t3.150686584100759\t0.8794910179640718\n",
      "Epoch:55\t0.05172556124936725\t0.9835267690003744\t3.3140304525060404\t0.8839820359281437\n",
      "Epoch:56\t0.06426653015514157\t0.9834331710969674\t3.1787232855157592\t0.8839820359281437\n",
      "Epoch:57\t0.053415685404124995\t0.9833395731935605\t3.3936349085476425\t0.8772455089820359\n",
      "Epoch:58\t0.054741033350970816\t0.9846499438412579\t3.3655965068863565\t0.8817365269461078\n",
      "Epoch:59\t0.0906230791066403\t0.9804380381879446\t3.717629591685912\t0.8817365269461078\n",
      "Epoch:60\t0.046623455119694526\t0.9849307375514789\t3.788294851605753\t0.8735029940119761\n",
      "Epoch:61\t0.045980289239892884\t0.9836203669037814\t3.760636103628147\t0.8787425149700598\n",
      "Epoch:62\t0.054220593943081534\t0.9832459752901535\t3.646948582365618\t0.8817365269461078\n",
      "Epoch:63\t0.05757588141864697\t0.9840883564208162\t4.320216312283302\t0.8794910179640718\n",
      "Epoch:64\t0.056417978901643184\t0.9852115312616997\t4.225653889603821\t0.8862275449101796\n",
      "Epoch:65\t0.048628725419560065\t0.9859603144889555\t4.084047986453062\t0.8817365269461078\n",
      "Epoch:66\t0.05315127441269775\t0.9843691501310371\t4.052381075454827\t0.8824850299401198\n",
      "Epoch:67\t0.06820040651083678\t0.984556345937851\t4.361311564511065\t0.875748502994012\n",
      "Epoch:68\t0.08413422706889441\t0.9777236989891427\t4.240976526112386\t0.8772455089820359\n",
      "Epoch:69\t0.05934911292821474\t0.9849307375514789\t4.252502995454473\t0.8854790419161677\n",
      "Epoch:70\t0.032844870004665114\t0.9868962935230251\t4.132444517906236\t0.8809880239520959\n",
      "Epoch:71\t0.037600722129117685\t0.986989891426432\t4.257454329910424\t0.8832335329341318\n",
      "Epoch:72\t0.05701049448497762\t0.9839011606140022\t4.313673517564057\t0.8802395209580839\n",
      "Epoch:73\t0.034447230685365926\t0.9877386746536878\t4.496839397042804\t0.8847305389221557\n",
      "Epoch:74\t0.04448168856821894\t0.9867090977162112\t4.547737705924614\t0.8839820359281437\n",
      "Epoch:75\t0.044635363703472736\t0.9868962935230251\t4.405650450652058\t0.8884730538922155\n",
      "Epoch:76\t0.050001182947980116\t0.9821228004492699\t4.027106404935833\t0.8817365269461078\n",
      "Epoch:77\t0.05834694829443564\t0.986989891426432\t4.445637941538113\t0.8877245508982036\n",
      "Epoch:78\t0.03395739129261825\t0.9880194683639086\t4.378105692486287\t0.8832335329341318\n",
      "Epoch:79\t0.04239865386112214\t0.9865219019093973\t4.169809120795701\t0.8869760479041916\n",
      "Epoch:80\t0.03874945987660591\t0.9867090977162112\t4.2722092251448505\t0.8817365269461078\n",
      "Epoch:81\t0.04087335343487459\t0.9880194683639086\t4.417367778433428\t0.8892215568862275\n",
      "Epoch:82\t0.03425198855521927\t0.9880194683639086\t4.6037547736408975\t0.8802395209580839\n",
      "Epoch:83\t0.06218542025572915\t0.9817484088356421\t4.514707272089613\t0.8794910179640718\n",
      "Epoch:84\t0.03841410333132299\t0.9877386746536878\t4.785600758109957\t0.8907185628742516\n",
      "Epoch:85\t0.05100136280804669\t0.9876450767502808\t4.8834189254031\t0.8854790419161677\n",
      "Epoch:86\t0.0749607202098816\t0.9840883564208162\t5.5514944273472215\t0.874251497005988\n",
      "Epoch:87\t0.07140592266510294\t0.9823099962560838\t4.995889097981909\t0.8839820359281437\n",
      "Epoch:88\t0.04012065096746776\t0.9890490453013853\t5.589605488944811\t0.8839820359281437\n",
      "Epoch:89\t0.048693830114378577\t0.9882066641707226\t5.490898577698566\t0.8862275449101796\n",
      "Epoch:90\t0.03257058652722559\t0.9892362411081992\t5.145013352604645\t0.8869760479041916\n",
      "Epoch:91\t0.037218801056938984\t0.9877386746536878\t4.9543412336211325\t0.8832335329341318\n",
      "Epoch:92\t0.026971165519611127\t0.9889554473979782\t5.420786600674067\t0.8869760479041916\n",
      "Epoch:93\t0.03779789863498738\t0.9884874578809435\t5.3777296622974955\t0.8787425149700598\n",
      "Epoch:94\t0.02543087477241709\t0.98951703481842\t5.477167623546279\t0.8824850299401198\n",
      "Epoch:95\t0.06275634059135371\t0.9857731186821416\t5.627458952168982\t0.8832335329341318\n",
      "Epoch:96\t0.0329636114421154\t0.9888618494945713\t5.7864624487450165\t0.8862275449101796\n",
      "Epoch:97\t0.04846491463537255\t0.9866154998128042\t5.552195736106046\t0.8802395209580839\n",
      "Epoch:98\t0.04270849862843991\t0.9868962935230251\t5.954454369898029\t0.8794910179640718\n",
      "Epoch:99\t0.024761912732065048\t0.9890490453013853\t5.816574020790725\t0.8929640718562875\n",
      "Epoch:100\t0.06245927456229091\t0.987083489329839\t6.002891469343288\t0.8847305389221557\n"
     ]
    }
   ],
   "source": [
    "train(256, 100, 0.01, \"./work/train_x.npy\", \"./work/train_y.npy\", \"./work/valid_x.npy\", \"./work/valid_y.npy\", \"./work/model79.pt\", \"./work/log79.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calc_loss_and_accuracy(model, loss_func, dataset):\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    gold_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    for x, y in dataset:\n",
    "        logit = model.forward(x)\n",
    "        loss = loss_func(logit, y)\n",
    "        total_loss += loss.item()\n",
    "        pred_label = torch.argmax(softmax(logit), dim=-1)\n",
    "        pred_labels.append(pred_label)\n",
    "        gold_labels.append(y)\n",
    "    ave_loss = total_loss / len(dataset)\n",
    "    accuracy = accuracy_score(gold_labels, pred_labels)\n",
    "    \n",
    "    return ave_loss, accuracy\n",
    "    \n",
    "def train(batch_size, num_epoch, learning_rate, train_x_file, train_y_file, valid_x_file, valid_y_file, output_file, log_file):\n",
    "    train_x = np.load(train_x_file)\n",
    "    train_y = np.load(train_y_file)\n",
    "    valid_x = np.load(valid_x_file)\n",
    "    valid_y = np.load(valid_y_file)\n",
    "    train_x = torch.from_numpy(train_x).float()\n",
    "    train_y = torch.from_numpy(train_y).long()\n",
    "    valid_x = torch.from_numpy(valid_x).float()\n",
    "    valid_y = torch.from_numpy(valid_y).long()\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    valid_dataset = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset,shuffle = True)\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_dataset)\n",
    "    model = Multipled_model(input_dim=300, hidden_dim=100,output_dim=4)\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #optimizerを変更\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "         \n",
    "    with open(log_file, \"w\") as f_log:\n",
    "        f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\"))\n",
    "        # 訓練 \n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(\"Epoch\", \"Train_loss\", \"Train_acc\", \"Valid_loss\", \"Valid_acc\"))\n",
    "        for epoch in range(1, num_epoch+1):\n",
    "            \n",
    "            for x, y in train_iter:\n",
    "                optimizer.zero_grad()\n",
    "                logit = model(x)\n",
    "                loss = loss_func(logit, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            #評価\n",
    "            train_loss, train_acc = calc_loss_and_accuracy(model, loss_func, train_iter)\n",
    "            valid_loss, valid_acc = calc_loss_and_accuracy(model, loss_func, valid_iter)\n",
    "            print(\"Epoch:{}\\t{}\\t{}\\t{}\\t{}\".format(epoch, train_loss, train_acc, valid_loss, valid_acc))\n",
    "            f_log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "            \n",
    "        #model.state_dictメソッドでモデルのパラメータを保存できる\n",
    "        #optimizer.state_dict()→内部状態を保存するメソッド\n",
    "        torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()} , output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU上で学習した結果を表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
